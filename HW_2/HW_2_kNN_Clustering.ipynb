{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# kNN & Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Суммарное количество баллов: 10 + 3 bonus__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN, рак и спам\n",
    "\n",
    "В этом части домашнего задания Вам предлагается при помощи классификации методом k ближайших соседей научиться отличать тип опухоли в организме, а так же определять сообщения со спамом"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 1 (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (0.5 балла)\n",
    "Реализуйте методы `read_cancer_dataset` и `read_spam_dataset`. Каждый из них принимает на вход путь к набору данных и возвращает выборку `X` и соответствующие метки `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CANCER_DATA_PATH = 'hw2_data/cancer.csv'\n",
    "SPAM_DATA_PATH = 'hw2_data/spam.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_cancer_dataset(path_to_csv):\n",
    "    '''\n",
    "    Возвращает пару из X и y. \n",
    "    X - массив векторов. \n",
    "    y - соответствующие векторам метки\n",
    "    '''\n",
    "    data = pd.read_csv(path_to_csv)\n",
    "    X = data.drop('label', axis=1)\n",
    "    y = data['label']\n",
    "    \n",
    "    return X, y\n",
    "\n",
    "def read_spam_dataset(path_to_csv):\n",
    "    '''\n",
    "    Возвращает пару из X и y. \n",
    "    X - массив векторов. \n",
    "    y - соответствующие векторам метки\n",
    "    '''\n",
    "    data = pd.read_csv(path_to_csv)\n",
    "    X = data.drop('label', axis=1)\n",
    "    y = data['label']\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cancer, y_cancer = read_cancer_dataset(CANCER_DATA_PATH)\n",
    "X_spam, y_spam = read_spam_dataset(SPAM_DATA_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (0.5 балла) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Начиная работать с данными, нам необходимо их предобработать и подготовить. В частности, нам необходимо разделить выборку на две: тренировочную и тестовую. Тренировочная выборка необходима для обучения алгоритма, а тестовая для проверки результатов обучения. Обычно используют коэффициент разделения `0.9`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(X, y, ratio=0.9):\n",
    "    '''\n",
    "    Возвращает X_train, y_train, X_test, y_test\n",
    "    X_train и X_test - массив векторов - две части массива X, \n",
    "    разделенного в состветсви с коэффициентом ratio.\n",
    "    y_train и y_test - соответствующие X_train и X_test метки классов\n",
    "    '''\n",
    "    \n",
    "    test_size = int(X.shape[0] * (1-ratio))\n",
    "    test_indexes = np.random.choice(X.index,\n",
    "                                    size=test_size,\n",
    "                                    replace=False)\n",
    "    X_train = X.drop(test_indexes)\n",
    "    y_train = y.drop(test_indexes)\n",
    "    \n",
    "    X_test = X.loc[test_indexes]\n",
    "    y_test = y.loc[test_indexes]\n",
    "    \n",
    "    return X_train, y_train, X_test, y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 2 (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также прежде чем приступать к решению задачи, нам необходимо определиться с метриками, которые позволят нам оценить полученное решение. Для задач классификации мы можем использовать precision, recall и accuracy. Эти метрики считаются для каждого класса. \n",
    "\n",
    "__Precision__ отражает то, насколько редко мы ошибаемся, когда говорим, что объект пренадлежит к классу. \n",
    "\n",
    "__Recall__ же отражает то, насколько редко классификатор неправильно классифицирует объекты данного класса.\n",
    "\n",
    "__Accuracy__ отражает то, какую часть выборки классификатор отнес к правильному классу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_precision_recall_accuracy(y_pred, y_true):\n",
    "    '''\n",
    "    Возвращает precision, recall и accuracy\n",
    "    precision - набор значений метрики precision для каждого класса\n",
    "    recall - набор значений метрики recall для каждого класса\n",
    "    accuracy - число, отражающее общую точность предсказания\n",
    "    '''\n",
    "    \n",
    "    classes = pd.concat([y_pred, y_true]).unique()\n",
    "    \n",
    "    precision = {}\n",
    "    recall = {}\n",
    "    for cls in classes:\n",
    "        true_cls = y_true == cls\n",
    "        pred_cls = y_pred == cls\n",
    "        \n",
    "        TP = (true_cls & pred_cls).sum()\n",
    "        FP = (-true_cls & pred_cls).sum()\n",
    "        FN = (true_cls & -pred_cls).sum()\n",
    "        \n",
    "        precision[cls] = TP / (TP + FP)\n",
    "        recall[cls] = TP / (TP + FN)\n",
    "        \n",
    "    accuracy = (y_pred == y_true).sum() / y_true.size\n",
    "    \n",
    "    return precision, recall, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_cancer_shfl = y_cancer.copy()\n",
    "# np.random.shuffle(y_cancer_shfl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'M': 0.41509433962264153, 'B': 0.6526610644257703},\n",
       " {'M': 0.41509433962264153, 'B': 0.6526610644257703},\n",
       " 0.5641476274165202)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get_precision_recall_accuracy(y_cancer, y_cancer_shfl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь, имея этот метод, мы можем построить кривые зависимости Precision, Recall и Accuracy от параметра `k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_precision_recall(X_train, y_train, X_test, y_test, max_k=30):\n",
    "    ks = list(range(1, max_k + 1))\n",
    "    classes = len(np.unique(list(y_train) + list(y_test)))\n",
    "    precisions = [[] for _ in range(classes)]\n",
    "    recalls = [[] for _ in range(classes)]\n",
    "    accuracies = []\n",
    "    for k in ks:\n",
    "        classifier = KNearest(k)\n",
    "        classifier.fit(X_train, y_train)\n",
    "        y_pred = classifier.predict(X_test)\n",
    "        precision, recall, acc = get_precision_recall_accuracy(y_pred, y_test)\n",
    "        for c in range(classes):\n",
    "            precisions[c].append(precision[c])\n",
    "            recalls[c].append(recall[c])\n",
    "        accuracies.append(acc)\n",
    "    def plot(x, ys, ylabel, legend=True):        \n",
    "        plt.figure(figsize = (12, 3))\n",
    "        plt.xlabel(\"K\")\n",
    "        plt.ylabel(ylabel)\n",
    "        plt.xlim(x[0], x[-1])\n",
    "        plt.ylim(np.min(ys)-0.01, np.max(ys)+0.01)\n",
    "        for cls, cls_y in enumerate(ys):\n",
    "            plt.plot(x, cls_y, label=\"Class \" + str(cls))\n",
    "        if legend:\n",
    "            plt.legend()\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    plot(ks, recalls, \"Recall\")\n",
    "    plot(ks, precisions, \"Precision\")\n",
    "    plot(ks, [accuracies], \"Accuracy\", legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также для оценки качества классификации построим __ROC-кривую__. Она отражает зависимость __True Positive Rate__ (TPR) от __False Positive Rate__ (FPR) для заранее фиксированного класса. Чем график выше побочной диагонали - тем лучше."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(X_train, y_train, X_test, y_test, max_k=30):\n",
    "    positive_samples = sum(1 for y in y_test if y == 0)\n",
    "    ks = list(range(1, max_k + 1))\n",
    "    curves_tpr = []\n",
    "    curves_fpr = []\n",
    "    colors = []\n",
    "    for k in ks:\n",
    "        colors.append([k / ks[-1], 0, 1 - k / ks[-1]])\n",
    "        knearest = KNearest(k)\n",
    "        knearest.fit(X_train, y_train)\n",
    "        p_pred = [p[0] for p in knearest.predict_proba(X_test)]\n",
    "        tpr = []\n",
    "        fpr = []\n",
    "        for w in np.arange(-0.01, 1.02, 0.01):\n",
    "            y_pred = [(0 if p > w else 1) for p in p_pred]\n",
    "            tpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt == 0) / positive_samples)\n",
    "            fpr.append(sum(1 for yp, yt in zip(y_pred, y_test) if yp == 0 and yt != 0) / (len(y_test) - positive_samples))\n",
    "        curves_tpr.append(tpr)\n",
    "        curves_fpr.append(fpr)\n",
    "    plt.figure(figsize = (7, 7))\n",
    "    for tpr, fpr, c in zip(curves_tpr, curves_fpr, colors):\n",
    "        plt.plot(fpr, tpr, color=c)\n",
    "    plt.plot([0, 1], [0, 1], linestyle=\"--\")\n",
    "    plt.xlabel(\"False positive rate\")\n",
    "    plt.ylabel(\"True positive rate\")\n",
    "    plt.xlim(-0.01, 1.01)\n",
    "    plt.ylim(-0.01, 1.01)\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 3  (3 балла)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. (2 балла)\n",
    "Осталось реализовать сам классификатор. Реализуйте его, используя KD-дерево. (При желании можно воспользоваться библиотечной реализацией дерева)\n",
    "\n",
    "Метод `__init__` принимает на вход количество соседей, по которым предсказывается класс, и размер листьев KD-дерева.\n",
    "\n",
    "Метод `fit` должен по набору данных и меток \"обучать\" классификатор. \n",
    "\n",
    "Метод `predict_proba` должен предсказывать вероятности классов для заданного набора данных основываясь на классах соседей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KNearest:\n",
    "    def __init__(self, n_neighbors=5, leaf_size=30):\n",
    "        self.k = n_neighbors\n",
    "        self.leaf_size = leaf_size\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.kdtree = {}\n",
    "        \n",
    "        unique_count = lambda x: np.unique(x).size\n",
    "        features = X.apply(unique_count).sort_values(ascending=False).index\n",
    "        \n",
    "        def make_branch(node, indices, level=0):\n",
    "            node['elements'] = indices\n",
    "            node['size'] = X.loc[indices].shape[0]\n",
    "            \n",
    "            if node['size'] > self.leaf_size:\n",
    "                try:\n",
    "                    feature = features[level]\n",
    "                except KeyError:\n",
    "                    level = 0\n",
    "                    feature = features[level]\n",
    "                    \n",
    "                edge = X.loc[indices][feature].median()\n",
    "                dichotomy = X.loc[indices][feature] < edge\n",
    "            \n",
    "                node['feature'] = feature\n",
    "                node['edge'] = edge\n",
    "                node[0] = {}\n",
    "                node[1] = {}\n",
    "                \n",
    "                make_branch(node[0], indices[dichotomy], level+1)\n",
    "                make_branch(node[1], indices[-dichotomy], level+1)\n",
    "                \n",
    "        make_branch(self.kdtree, X.index)\n",
    "            \n",
    "        \n",
    "    def predict_proba(self, X):\n",
    "        # Возвращает матрицу, в которой строки соответствуют элементам X, а столбцы - классам. На пересечении строки и столбца должна быть указана вероятность того, что элемент относится к классу\n",
    "        # Вероятность рассчитывается как количество ближайших соседей с данным классом деленное на общее количество соседей\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        return np.argmax(self.predict_proba(X), axis=1)\n",
    "\n",
    "    \n",
    "    def _k_nearest(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn = KNearest()\n",
    "knn.fit(X_cancer, y_cancer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "capital_run_length_average    2161\n",
       "char_freq_!                    964\n",
       "capital_run_length_total       919\n",
       "char_freq_(                    641\n",
       "word_freq_you                  575\n",
       "char_freq_$                    504\n",
       "word_freq_your                 401\n",
       "word_freq_hp                   395\n",
       "word_freq_will                 316\n",
       "char_freq_#                    316\n",
       "char_freq_:                    313\n",
       "word_freq_hpl                  281\n",
       "capital_run_length_longest     271\n",
       "word_freq_our                  255\n",
       "word_freq_free                 253\n",
       "word_freq_mail                 245\n",
       "word_freq_george               240\n",
       "word_freq_re                   230\n",
       "word_freq_email                229\n",
       "word_freq_edu                  227\n",
       "char_freq_[                    225\n",
       "word_freq_all                  214\n",
       "word_freq_650                  200\n",
       "word_freq_business             197\n",
       "word_freq_1999                 188\n",
       "word_freq_meeting              186\n",
       "word_freq_data                 184\n",
       "word_freq_labs                 179\n",
       "word_freq_85                   177\n",
       "word_freq_remove               173\n",
       "word_freq_address              171\n",
       "word_freq_internet             170\n",
       "word_freq_000                  164\n",
       "word_freq_pm                   163\n",
       "word_freq_project              160\n",
       "word_freq_technology           159\n",
       "word_freq_people               158\n",
       "word_freq_lab                  156\n",
       "word_freq_credit               148\n",
       "word_freq_order                144\n",
       "word_freq_money                143\n",
       "word_freq_make                 142\n",
       "word_freq_over                 141\n",
       "word_freq_original             136\n",
       "word_freq_report               133\n",
       "word_freq_telnet               128\n",
       "word_freq_direct               125\n",
       "word_freq_addresses            118\n",
       "word_freq_receive              113\n",
       "word_freq_415                  110\n",
       "word_freq_cs                   108\n",
       "word_freq_857                  106\n",
       "word_freq_conference           106\n",
       "word_freq_font                  99\n",
       "word_freq_parts                 53\n",
       "word_freq_3d                    43\n",
       "word_freq_table                 38\n",
       "dtype: int64"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_spam.apply(lambda x: np.unique(x).size).sort_values(ascending=False).index\n",
    "\n",
    "# pd.Series.sort_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Наконец, протестируем наш классификатор на различных наборах данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(X_cancer, y_cancer, 0.9)\n",
    "plot_precision_recall(X_train, y_train, X_test, y_test)\n",
    "plot_roc_curve(X_train, y_train, X_test, y_test, max_k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_test, y_test = train_test_split(X_spam, y_spam, 0.9)\n",
    "plot_precision_recall(X_train, y_train, X_test, y_test, max_k=20)\n",
    "plot_roc_curve(X_train, y_train, X_test, y_test, max_k=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (1.5 балла)\n",
    "\n",
    "Проанализируйте полученные графики. Какой параметр `k` кажется лучшим для каждой из задач? Какая из метрик лучше всего отражает качество модели? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ваш ответ_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В этой части домашнего задания предлагается реализовать три различных метода кластеризации, понять, в каких случаях стоит применять те или иные методы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KDTree\n",
    "from sklearn.datasets import make_blobs, make_moons, make_swiss_roll\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import copy\n",
    "import cv2\n",
    "from collections import deque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_clasters(X, labels):\n",
    "    unique_labels = np.unique(labels)\n",
    "    unique_colors = np.random.random((len(unique_labels), 3))\n",
    "    colors = [unique_colors[l] for l in labels]\n",
    "    plt.figure(figsize=(9, 9))\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=colors)\n",
    "    plt.show()\n",
    "\n",
    "def clusters_statistics(flatten_image, cluster_colors, cluster_labels):\n",
    "    fig, axes = plt.subplots(3, 2, figsize=(12, 16))\n",
    "    for remove_color in range(3):\n",
    "        axes_pair = axes[remove_color]\n",
    "        first_color = 0 if remove_color != 0 else 2\n",
    "        second_color = 1 if remove_color != 1 else 2\n",
    "        axes_pair[0].scatter([p[first_color] for p in flatten_image], [p[second_color] for p in flatten_image], c=flatten_image, marker='.')\n",
    "        axes_pair[1].scatter([p[first_color] for p in flatten_image], [p[second_color] for p in flatten_image], c=[cluster_colors[c] for c in cluster_labels], marker='.')\n",
    "        for a in axes_pair:\n",
    "            a.set_xlim(0, 1)\n",
    "            a.set_ylim(0, 1)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерируем два синтетических набора данных для кластеризации. Далее будем тестировать наши алгоритмы на них."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, true_labels = make_blobs(400, 2, centers=[[0, 0], [-4, 0], [3.5, 3.5], [3.5, -2.0]])\n",
    "visualize_clasters(X_1, true_labels)\n",
    "X_2, true_labels = make_moons(400, noise=0.075)\n",
    "visualize_clasters(X_2, true_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 4 (1.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Первый метод, который предлагается реализовать - метод K средних.\n",
    "\n",
    "__Описание методов__\n",
    "\n",
    "`fit(X, y=None)` ищет и запоминает в `self.centroids` центроиды кластеров для набора данных.\n",
    "`predict(X)` для каждого элемента из `X` возвращает номер кластера, к которому относится данный элемент.\n",
    "\n",
    "__Инициализация кластеров__\n",
    "\n",
    "Есть несколько вариантов инициализации кластеров. Нужно реализовать их все:\n",
    "1. `random` - центроиды кластеров являются случайными точками\n",
    "2. `sample` - центроиды кластеров выбираются случайно из набора данных\n",
    "3. `k-means++` - центроиды кластеров инициализируются при помощи метода K-means++\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KMeans:\n",
    "    def __init__(self, n_clusters, init=\"random\", max_iter=300):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def predict(self, X):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте алгоритм на синтетических данных. При необходимости подберите гиперпараметры для достижения лучшего качества кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X_1)\n",
    "labels = kmeans.predict(X_1)\n",
    "visualize_clasters(X_1, labels)\n",
    "\n",
    "kmeans = KMeans(n_clusters=2)\n",
    "kmeans.fit(X_2)\n",
    "labels = kmeans.predict(X_2)\n",
    "visualize_clasters(X_2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 5 (2 балла)\n",
    "В отличии от K-means, DBScan не позволяет задать количество кластеров, на которое будут разбиты данные. Руководствуясь геометрической интерпретацией, он позволяет выделять кластеры более сложной формы.\n",
    "\n",
    "__Описание методов__\n",
    "\n",
    "`fit_predict(X, y=None)` для каждого элемента `X` возвращает метку кластера, к которому он относится.\n",
    "\n",
    "__Возможные метрики__\n",
    "\n",
    "* `euclidean`\n",
    "* `manhattan`\n",
    "* `chebyshev`\n",
    "\n",
    "__Для быстрого поиска соседей используйте `sklearn.neighbors.KDTree`__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DBScan:\n",
    "    def __init__(self, eps=0.5, min_samples=5, leaf_size=40, metric=\"euclidean\"):\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "    def fit_predict(self, X, y=None):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте алгоритм на синтетических данных. При необходимости подберите гиперпараметры для достижения лучшего качества кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dbscan = DBScan()\n",
    "labels = dbscan.fit_predict(X_1)\n",
    "visualize_clasters(X_1, labels)\n",
    "\n",
    "dbscan = DBScan()\n",
    "labels = dbscan.fit_predict(X_2)\n",
    "visualize_clasters(X_2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задание 6 (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Проанализируйте полученные результаты. \n",
    "\n",
    "Какой метод лучше справился с кластеризацией каждого из датасетов? Почему? \n",
    "\n",
    "Сравните значения метрик  `Davies-Bouldin index` и `Silhouette score` для определения качества кластеризации. \n",
    "\n",
    "Какие значения метрики свидетельствуют о хорошей кластеризации - большие или маленькие?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ваш ответ_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import davies_bouldin_score\n",
    "from sklearn.metrics import silhouette_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR_CODE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus. (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. (2.5 балла)\n",
    "\n",
    "Идея AgglomerativeClustering заключается в том, чтобы итеративно объединять кластеры с наименьшим расстоянием между ними. Данный метод обладает высокой вычислительной сложностью, поэтому применим только для относительно небольших наборов данных.\n",
    "\n",
    "__Описание методов__\n",
    "\n",
    "`fit_predict(X, y=None)` для каждого элемента `X` возвращает метку кластера, к которому он относится.\n",
    "\n",
    "__Linkage-функции__\n",
    "\n",
    "__Linkage__ - это способ, которым будет рассчитываться расстояние между кластерами. Предлагается реализовать три варианта такой функции:\n",
    "1. `average` - расстояние рассчитывается как среднее расстояние между всеми парами точек, где одна принадлежит первому кластеру, а другая - второму.\n",
    "2. `single` - расстояние рассчитывается как минимальное из расстояний между всеми парами точек, где одна принадлежит первому кластеру, а другая - второму.\n",
    "2. `complete` - расстояние рассчитывается как максимальное из расстояний между всеми парами точек, где одна принадлежит первому кластеру, а другая - второму."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AgglomertiveClustering:\n",
    "    def __init__(self, n_clusters=16, linkage=\"average\"):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def fit_predict(self, X, y=None):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Протестируйте алгоритм на синтетических данных. При необходимости подберите гиперпараметры для достижения лучшего качества кластеризации."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agg_clustering = AgglomertiveClustering(n_clusters=4)\n",
    "labels = agg_clustering.fit_predict(X_1)\n",
    "visualize_clasters(X_1, labels)\n",
    "\n",
    "agg_clustering = AgglomertiveClustering(n_clusters=2)\n",
    "labels = agg_clustering.fit_predict(X_2)\n",
    "visualize_clasters(X_2, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. (0.5 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравните значения метрик  `Davies-Bouldin index` и `Silhouette score` для `AgglomertiveClustering` с `K-means` и `DBSCAN`. \n",
    "\n",
    "Какой из методов лучше произвел кластеризацию данных?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Ваш ответ_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR_CODE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
